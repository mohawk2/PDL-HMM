#-*- Mode: Perl -*-

##======================================================================
## Header Administrivia
##======================================================================

our $VERSION = '0.01';
pp_setversion($VERSION);

##------------------------------------------------------
## pm additions
pp_addpm({At=>'Top'},<<'EOPM');
=pod

=head1 NAME

PDL::HMM - PDL Hidden Markov Model utilities

=head1 SYNOPSIS

 use PDL::HMM;

 ##-----------------------------------------------------
 ## todo

=cut

EOPM
## /pm additions
##------------------------------------------------------

##------------------------------------------------------
## Exports: None
#pp_export_nothing();

##------------------------------------------------------
## Includes / defines
pp_addhdr(<<'EOH');

#include <math.h>

/*#define DEBUG_ALPHA*/
/*#define DEBUG_BETA*/
/*#define DEBUG_VITERBI*/

EOH


##======================================================================
## C Utilities
##======================================================================

##----------------------------------------------------------------------
## Log addition
pp_addhdr(<<'EOH');

/* logadd(x,y) = log(exp(x)+exp(y))
 *   + Code from Manning & Schütze (1997), Sec. 9.4, page 337
 *
 * LOG_BIG = log(1E31)
 */
#define LOG_BIG    71.3801378828154
#define LOG_ZERO  -1E+38
#define LOG_ONE    0
#define LOG_NONE   1
double logadd(double x, double y) {
  if      (y-x > LOG_BIG) return y;
  else if (x-y > LOG_BIG) return x;
  /*else        return min(x,y) + log(exp(x-min(x,y)) + exp(y-min(x,y))); */
  else if (x<y) return x        + log( 1              + exp(y-x));
  else          return y        + log(exp(x-y)        + 1);
}
//#define logadd(x,y) log(exp(x)+exp(y))


/* logdiff(x,y) = log(exp(x)-exp(y))
 *   + adapted from above
 *   + always returns positive (i.e. symmetric difference)
 */
double logdiff(double x, double y) {
  if      (y-x > LOG_BIG) { return y; }
  else if (x-y > LOG_BIG) { return x; }
  /*else        { return max(x,y) + log(exp(max(x,y)-max(x,y)) - exp(min(x,y)-max(x,y))); } */
  /*                   = max(x,y) + log( 1 - exp(min(x,y)-max(x,y))); } */
  else if (x>y) { return x        + log( 1 - exp(y-x)); }
  else          { return y        + log( 1 - exp(x-y)); }
}

EOH


##======================================================================
## PDL::PP Wrappers
##======================================================================

##======================================================================
## Basic Utilities
pp_addpm(<<'EOPM');
=pod

=head1 Log Arithmetic

=cut
EOPM

##------------------------------------------------------
## logzero(): near approximation of log(0)
pp_def('logzero',
       Pars => 'float+ [o]a()',
       Inplace=>['a'], ##-- can run inplace on a()
       Code => '$a() = LOG_ZERO;',
       CopyBadStatusCode =>
	  (' if ( $ISPDLSTATEBAD(a) ) PDL->propogate_badflag(a,0);'
	   .'  $SETPDLSTATEGOOD(a);'),
       HandleBad=>1,
       Doc => 'Approximates $a() = log(0), avoids nan.',
       BadDoc => 'logzero() handles bad values.  The state of the output PDL is always good.',
      );


##------------------------------------------------------
## log addition: logadd(a,b) = log(exp(a)+exp(b))
pp_def('logadd',
       Pars => 'a(); b(); [o]c()',
       Inplace=>['a'], ##-- can run inplace on a()
       Code => '$c() = logadd($a(),$b());',
       Doc => 'Computes $c() = log(exp($a()) + exp($b())), should be more stable.',
      );

##------------------------------------------------------
## log subtraction: logdiff(a,b) = log(exp(max(a,b))-exp(min(a,b)))
pp_def('logdiff',
       Pars => 'a(); b(); [o]c()',
       Inplace=>['a'], ##-- can run inplace on a()
       Code => '$c() = logdiff($a(),$b());',
       Doc => 'Computes log symmetric difference c = log(exp(max(a,b)) - exp(min(a,b))), may be more stable.',
      );


##------------------------------------------------------
## log sum: logsumover(a) = log(sumover(exp(a)))
pp_def('logsumover',
       Pars => 'a(n); [o]b()',
       Code => (join("\n",
		     'double sum=LOG_ZERO;',
		     'loop (n) %{ sum = logadd($a(),sum); %}',
		     '$b() = sum;')),
       Doc => 'Computes $b() = log(sumover(exp($a()))), should be more stable.',
      );


##======================================================================
## Sequence Probability
pp_addpm(<<'EOPM');
=pod

=head1 Sequence Probability

=cut
EOPM


##------------------------------------------------------
## Forward probability: hmmfw(A,B,pi, O, [o]alpha)
pp_def
('hmmfw',
 Pars => 'a(N,N); b(N,M); pi(N);  o(T);  [o]alpha(N,T)',
 Code =>
('
 /*-- Initialize: t==0 --*/
 int i,j,t, o_tp1 = $o(T=>0);
 loop (N) %{
   $alpha(T=>0) = $pi() + $b(M=>o_tp1);

   #ifdef DEBUG_ALPHA
   printf("INIT: j=%u,t=0,o=%d:  pi(j=%u)=%.2e  b(j=%u,o=%d)=%.2e  alpha(j=%u,t=0)=%.2e\n",
	  n,o_tp1,
	  n,      exp($pi()),
	  n,o_tp1 exp($b(M=>o_tp1)),
	  n,      exp($alpha(T=>0))
	 );
   #endif
 %}

 #ifdef DEBUG_ALPHA
 printf("\n\n");
 #endif

 /*-- Loop: time t>0 --*/
 for (t=0; t < $SIZE(T)-1; t++) {
   o_tp1 = $o(T=>t+1);

   /*-- Loop: state_(t+1)==j --*/
   for (j=0; j<$SIZE(N); j++) {
     double alpha_j_tp1 = LOG_ZERO;


     /*-- Loop: state_t==i --*/
     for (i=0; i<$SIZE(N); i++) {
       alpha_j_tp1 = logadd( $alpha(N=>i,T=>t) + $a(N0=>i,N1=>j),  alpha_j_tp1 );

       #ifdef DEBUG_ALPHA
        printf("i=%u,j=%u,t=%u,o=%d:  alpha(i=%u,t=%u)=%.2e  a(i=%u,j=%u)=%.2e  b(j=%u,o=%d)=%.2e  prod=%.2e  sum=%.2e\n",
	       i,j,t,o_tp1,
	       i,t,     exp($alpha(N=>i,T=>t)),
	       i,j,     exp($a(N0=>i,N1=>j)),
	       j,o_tp1, exp($b(N=>j,M=>o_tp1)),
	       exp( $alpha(N=>i,T=>t) + $a(N0=>i,N1=>j) ), exp(alpha_j_tp1));
       #endif
     }

     /*-- Storage: alpha(time=t+1, state=j) --*/
     $alpha(N=>j,T=>t+1) = alpha_j_tp1 + $b(N=>j,M=>o_tp1);

     #ifdef DEBUG_ALPHA
      printf("----> alpha(j=%u,t=%u)=%.2E\n", j,t+1, exp($alpha(N=>j,T=>t+1)));
     #endif
   }
   #ifdef DEBUG_ALPHA
    printf("\n\n");
   #endif
 }
'),

Doc=>
  ('Compute forward probability (alpha) matrix
for input $o given model parameters
@theta = ($a, $b, $pi).

Output (pseudocode) for all 0<=i<N, 0<=t<T:

 $alpha(i,t) = log P( $o(0:t), q(t)==i | @theta )

Note that:

  log P( $o | @theta ) = logsumover( $alpha(:,t-1) )
'),

);

pp_addpm('*hmmalpha = \&hmmfw;');
pp_add_exported('','hmmalpha');


##------------------------------------------------------
## Backward probability: hmmbw(A,B, O, [o]beta)
pp_def
#@l=
('hmmbw',
 Pars => 'a(N,N); b(N,M); o(T); [o]beta(N,T)',
 Code =>
('
 int i,j,t = $SIZE(T)-1;

 /*-- Initialize: time t==T --*/
 loop(N) %{ $beta(T=>t) = LOG_ONE; %}

 /*-- Loop: time t < T --*/
 for (t--; t >= 0; t--) {
   int o_tp1 = $o(T=>t+1);

   /*-- Loop: t<T: state_t == i  --*/
   for (i=0; i<$SIZE(N); i++) {
     double beta_i_t = LOG_ZERO;

     /*-- Loop: t<T: state_(t+1) == i  --*/
     for (j=0; j<$SIZE(N); j++) {
       beta_i_t = logadd( $a(N0=>i,N1=>j) + $b(N=>j,M=>o_tp1) + $beta(N=>j,T=>t+1) ,  beta_i_t );

       #ifdef DEBUG_BETA
       printf("i=%u,j=%u,t=%u,o=%d:  a(i=%u,j=%u)=%.2e  b(j=%u,o=%u)=%.2e  beta(j=%u,t+1=%u)=%.2e   prod=%.2e  sum=%.2e\n",
	      i,j,t,o_tp1,
	      i,j,    exp($a(N0=>i,N1=>j)),
	      j,o_t,  exp($b(N=>j,M=>o_t)),
	      j,t+1,  exp($beta(N=>j,T=>t+1)),
	      exp($a(N0=>i,N1=>j)+$b(N=>j,M=>o_t)+$beta(N=>j,T=>t+1)),  exp(beta_i_t));
       #endif
     }

     /*-- t<T: state_t == i: update  --*/
     $beta(N=>i,T=>t) = beta_i_t;

     #ifdef DEBUG_BETA
     printf("\n");
     #endif
   }
   #ifdef DEBUG_BETA
   printf("\n\n");
   #endif
 }
'
),

Doc=>
  ('Compute backward probability (beta) matrix
for input $o given model parameters
@theta = ($a, $b, $pi).

Output (pseudocode) for all 0<=i<N, 0<=t<T:

 $beta(i,t) = log P( $o(t+1:T-1) | q(t)==i, @theta )

Note that:

  log P( $o | @theta ) = logsumover( $pi() + $beta(:,0) )

'),

);


pp_addpm('*hmmbeta = \&hmmbw;');
pp_add_exported('','hmmbeta');


##======================================================================
## Parameter Estimation

##-- hmmexpect0() : initializer
pp_addpm(<<'EOPM');
=pod

=head1 Parameter Estimation

=head2 hmmexpect0

=for sig

  Signature: (a(N,N); b(N,M); pi(N); [o]ea(N,N); [o]eb(N,M); [o]epi(N))

Initializes expectation matrices $ea(), $eb() and $epi() to logzero().
For use with hmmexpect().

=cut

sub hmmexpect0 {
  my ($a,$b,$pi, $ea,$eb,$epi) = @_;

  $ea  = zeroes($a->type,  $a->dims)  if (!defined($ea));
  $eb  = zeroes($b->type,  $b->dims)  if (!defined($eb));
  $epi = zeroes($pi->type, $pi->dims) if (!defined($epi));

  $ea  .= PDL::logzero();
  $eb  .= PDL::logzero();
  $epi .= PDL::logzero();

  return ($ea,$eb,$epi);
}

EOPM

pp_add_exported('', 'hmmexpect0');


##------------------------------------------------------
## Partial re-estimation
pp_def
('hmmexpect',
 Pars => join("\n",
	      qw(a(N,N);
		 b(N,M);
		 pi(N);
		 o(T);
		 alpha(N,T);
		 beta(N,T);),
	      #qw([t]gamma_tp1(N);), ##-- (N) : gamma(N=>i, T=>(t+1))
	      qw([o]ea(N,N);
		 [o]eb(N,M);
		 [o]epi(N))),
 Code =>
('
 int i,j,t;
 int o_tp1, o_t;
 double p_o = LOG_ZERO;
 double gamma_it;
 double xi_ijt;

 /*-- Initialize: t==(T-1): P(o|@theta) --*/
 t = $SIZE(T)-1;
 loop (N) %{ p_o = logadd(p_o, $alpha(T=>t)); %}

 /*-- Initialize: t==(T-1): Iterate: state_t==i: get gamma(i,t) --*/
 o_t = $o(T=>t);
 for (i=0; i<$SIZE(N); i++) {
   $eb(N=>i,M=>o_t) = logadd($eb(N=>i,M=>o_t), $alpha(N=>i,T=>t) + $beta(N=>i,T=>t) - p_o);
 }

 /*-- Main: Iterate: T-1 > t >= 0 --*/
 for (t--; t>=0; t--) {
   o_tp1 = o_t;
   o_t   = $o(T=>t);

   /*-- Main: Iterate: state_t == i --*/
   for (i=0; i<$SIZE(N); i++) {
     gamma_it = $alpha(N=>i,T=>t) + $beta(N=>i,T=>t);

     /*-- Main: Iterate: state_(t+1) == j --*/
     for (j=0; j<$SIZE(N); j++) {
       xi_ijt = $alpha(N=>i,T=>t) + $a(N0=>i,N1=>j) + $b(N=>j,M=>o_tp1) + $beta(N=>j,T=>t+1) - p_o;

       $ea(N0=>i,N1=>j) = logadd(xi_ijt, $ea(N0=>i,N1=>j));
     }

     /*-- Main: Update: pi --*/
     if (t==0) $epi(N=>i) = logadd(gamma_it, $epi(N=>i));

     /*-- Main: Update: b --*/
     $eb(N=>i,M=>o_t)     = logadd(gamma_it, $eb(N=>i,M=>o_t));
   }
 }
'),

 Doc =>
  ('Compute partial Baum-Welch re-estimation of the model @theta = ($a, $b, $pi)
for the observation sequence $o() with forward- and backward-probability
matrices $alpha(), $beta().  Result is recorded as log pseudo-frequencies
in the expectation matrices $ea(), $eb(), and $epi(), which are required paramters,
and should have initialized (e.g. by hmmexpect0()) before calling this function.

Can safely be called sequentially for incremental reestimation.
'),
);


##-- hmmmaximize() : maximizer
pp_addpm(<<'EOPM');
=pod

=head2 hmmmaximize

=for sig

  Signature: (EA(n,n); EB(n,k); Epi(n); [o]Ahat(n,n); [o]Bhat(n,k); [o]pihat(n));

Maximizes expectation values from $EA(), $EB()m and $Epi()
to log-probability matricies $Ahat(), $Bhat(), and $pihat().
Can also be used to compile a maximum-likelihood model
from log-frequency matrices.

=cut

sub hmmmaximize {
  my ($EA,$EB,$Epi, $Ahat,$Bhat,$pihat) = @_;

  $Ahat  = zeroes($EA->type,  $EA->dims)  if (!defined($Ahat));
  $Bhat  = zeroes($EB->type,  $EB->dims)  if (!defined($Bhat));
  $pihat = zeroes($Epi->type, $Epi->dims) if (!defined($pihat));

  $Ahat  .= $EA  - $EA->xchg(0,1)->logsumover;
  $Bhat  .= $EB  - $EB->xchg(0,1)->logsumover;
  $pihat .= $Epi - $Epi->logsumover;

  return ($Ahat,$Bhat,$pihat);
}

EOPM

pp_add_exported('', 'hmmmaximize');


##======================================================================
## Sequence Analysis
pp_addpm(<<'EOPM');
=pod

=head1 Sequence Analysis

=cut
EOPM


##--------------------------------------------------------------
## Sequence Analysis: Viterbi
pp_def
('hmmviterbi',
 Pars => join("\n",
	      qw(a(N,N);
		 b(N,M);
		 pi(N);
		 o(T);
		 [o]delta(N,T);),
	         'int [o]psi(N,T)'),
 Code =>
('
 int i,j, t, o_t;
 double delta_jt, delta_tmp;
 int psi_jt;

 /*-- Initialize: t==0: Loop: state_0==N --*/
 o_t = $o(T=>0);
 loop (N) %{
   $delta(T=>0) = $pi() + $b(M=>o_t);
   $psi  (T=>0) = 0;
#ifdef DEBUG_VITERBI
   printf("t=0,j=%d,o_t=%d: delta(t=0,j=%d)=%.2e  psi(t=0,j=%d)=%.0g  b(j=%d,o=%d)=%.2e\n",
           N,o_t,
           N, exp($delta(T=>0)),
           N, $psi(T=>0),
           N,o_t, exp($b(M=>o_t)));
#endif
 %}

#ifdef DEBUG_VITERBI
   printf("\n");
#endif

 /*-- Main: t>0: Loop: time==t --*/
 for (t=1; t<$SIZE(T); t++) {
   o_t = $o(T=>t);

   /*-- Main: t>0: Loop: state_t==j --*/
   for (j=0; j<$SIZE(N); j++) {
     psi_jt   = 0;
     delta_jt = $delta(N=>0,T=>t-1) + $a(N0=>0,N1=>j);

     /*-- Main: t>0: Loop: state_(t-1)==i --*/
     for (i=1; i<$SIZE(N); i++) {
       delta_tmp = $delta(N=>i,T=>t-1) + $a(N0=>i,N1=>j);

       if (delta_tmp > delta_jt) {
	 delta_jt = delta_tmp;
	 psi_jt   = i;
#ifdef DEBUG_VITERBI
         printf("+");
#endif
       }

#ifdef DEBUG_VITERBI
       printf("t=%d,i=%d,j=%d,o_t=%d:  deltaX(i=%d,t=%d)=%.2e  psi(j=%d,t=%d)=%.0g  delta(j=%d,t=%d)=%.2e\n",
              t,i,j,o_t,
              i,t,  exp(delta_tmp),
              j,t,  psi_jt,
              j,t,  exp(delta_jt));
#endif
     }

     /*-- Main: t>0: Store data for state,time=(j,t) --*/
     $delta(N=>j,T=>t) = delta_jt + $b(N=>j,M=>o_t);
     $psi  (N=>j,T=>t) = psi_jt;

#ifdef DEBUG_VITERBI
     printf("\n---> t=%d: b(j=%d,o=%d)=%.2e  delta(j=%d,t=%d)=%.2e  psi(j=%d,t=%d)=%.0g\n\n",
            t, j,o_t, exp($b(N=>j,M=>o_t)),
            j,t,      exp($delta(N=>j,T=>t)),
            j,t,      $psi(N=>j,T=>t));
#endif
   }
#ifdef DEBUG_VITERBI
   printf("\n");
#endif
 }
'),
  Doc =>
  ('Computes Viterbi algorithm trellises $delta() and $gamma() for the
observation sequence $o() given the model parameters @theta = ($a,$b,$pi).

Outputs:

Probability matrix $delta(): log probability of best path to state $j at time $t:

 $delta(j,t) = max_{q(0:t)} log P( $o(0:t), q(0:t-1), $q(t)==j | @theta )

Path backtrace matrix $psi(): best predecessor for state $j at time $t:

 $psi(j,t) = arg_{q(t-1)} max_{q(0:t)} P( $o(0:t), q(0:t-1), $q(t)==j | A,B,pi )

'),
);


##--------------------------------------------------------------
## Sequence Analysis: Backtrace
pp_def
('hmmpath',
 Pars => q(psi(N,T); int qfinal(); int [o]path(T)),
 Code =>
('
 /*-- Initialize: t==T-1: state_(t)==final() --*/
 int t = $SIZE(T)-1;
 $path(T=>t) = $qfinal();

 /*-- Main: T-1 > t >= 0: Loop: time==t --*/
 for (t--; t>=0; t--) {
   int q_tp1   = $path(T=>t+1);
   $path(T=>t) = $psi (T=>t+1,N=>q_tp1);
 }
'),
  Doc =>
  ('Computes best-path backtrace $path() for the final state $qfinal()
from completed Viterbi trellises $delta() and $psi.

Outputs:

Path backtrace $path(): state (in best sequence) at time $t:

 $path(t) = arg_{q(t)} max_{q(0:T-1)} log P( $o(), q(0:T-2), $q(T-1)==$qfinal() | @theta )

Note: to find the single best path, just set:

 $qfinal = maximum_ind($delta->slice(",".($T-1)));

Wow. PDL is great.  I bet that this entire module could be written
without PDL::PP, but hey -- it\'s here now, so what the heck...
'),
);



##======================================================================
## Footer Administrivia
##======================================================================

##------------------------------------------------------
## pm additions
pp_addpm(<<'EOPM');


##---------------------------------------------------------------------
=pod

=head1 COMMON PARAMETERS

HMMs are specified by parameters $A(n,n) and $B(n,k),
where the following hold:

=over 4

=item Time indices:

Time indices are denoted $t,
1 <= $t < $T.


=item States:

The model has $N states, denoted $q,
0 <= $q(t) < $N.


=item Alphabet:

The input- (observation-) alphabet of the model has $M elements,
denoted $o, 0 <= $o(t) < $M.


=item Initial Probabilities:

The vector $pi(N) gives the (log) initial state probability distribution:

 $pi(i) = log P( $q(0)==i )


=item Arc Probabilities:

The matrix $a(N,N) gives the (log) conditional state-transition probability distribution:

 $a(i,j) = log P( $q(t+1)==j | $q(t)==i )


=item Emission Probabilities:

The matrix $b(N,M) gives the (log) conditional symbol emission probability:

 $b(j,o) = log P( $o(t)==o | $q(t)==j )


=item Input Sequences:

Observation sequences are represented by vectors of alphabet indices
(of length $T); sequence values are
used as indices into the model parameters $A(), $B(), and $pi().


=back

=cut

##---------------------------------------------------------------------
=pod

=head1 ACKNOWLEDGEMENTS

Perl by Larry Wall.

PDL by Karl Glazebrook, Tuomas J. Lukka, Christian Soeller, and others.

Implementation based on the formulae in:
L. E. Rabiner, "A tutorial on Hidden Markov Models and selected
applications in speech recognition," Proceedings of the IEEE 77:2,
Februrary, 1989, pages 257--286.

=cut

##----------------------------------------------------------------------
=pod

=head1 KNOWN BUGS

Probably many.

=cut


##---------------------------------------------------------------------
=pod

=head1 AUTHOR

Bryan Jurish E<lt>moocow@ling.uni-potsdam.deE<gt>

=head2 Copyright Policy

Copyright (C) 2005, Bryan Jurish. All rights reserved.

This package is free software, and entirely without warranty.
You may redistribute it and/or modify it under the same terms
as Perl itself.

=head1 SEE ALSO

perl(1), PDL(3perl).

=cut

EOPM


# Always make sure that you finish your PP declarations with
# pp_done
pp_done();
##----------------------------------------------------------------------
